{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94def1d5-11ad-4aa0-a41a-60b05f953e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## main\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from PIL import Image\n",
    "\n",
    "## skelarn -- preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "## skelarn -- models\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## sklearn -- metrics\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb767f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39477467",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join(os.getcwd(), \"dataset.csv\")\n",
    "df = pd.read_csv(TRAIN_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4608033",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"CustomerId\" , \"RowNumber\" , \"Surname\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32d24c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68041496",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4905a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efacce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum() # check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0803095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6f96e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierHandler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, method=\"iqr\", factor=1.5):\n",
    "        self.method = method\n",
    "        self.factor = factor\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        if self.method == \"iqr\":\n",
    "            Q1 = np.percentile(X, 25, axis=0)\n",
    "            Q3 = np.percentile(X, 75, axis=0)\n",
    "            IQR = Q3 - Q1\n",
    "            self.lower_bound_ = Q1 - self.factor * IQR\n",
    "            self.upper_bound_ = Q3 + self.factor * IQR\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = np.where(X < self.lower_bound_, self.lower_bound_, X)\n",
    "        X = np.where(X > self.upper_bound_, self.upper_bound_, X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ab1a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To features and target\n",
    "X = df.drop(columns=['Exited'], axis=1)\n",
    "y = df['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaef9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X , y , test_size=0.2 , random_state=42 , stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dce05c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "num_cols = ['Age', 'CreditScore', 'Tenure', 'Balance' , 'EstimatedSalary'] \n",
    "ready_cols = ['NumOfProducts' ,'HasCrCard' ,'IsActiveMember']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c69e705",
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0336af",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline(steps = [\n",
    "    ('imputer' , SimpleImputer(strategy='median')),\n",
    "    ('outlier_handler' , OutlierHandler(method='iqr', factor=1.5)),\n",
    "    ('scaler' , RobustScaler())\n",
    "])\n",
    "\n",
    "categ_pipline = Pipeline(steps=[\n",
    "    ('imputer' , SimpleImputer(strategy='most_frequent')),\n",
    "    (\"ohe\" , OneHotEncoder(handle_unknown='ignore' , drop='first'))\n",
    "])\n",
    "\n",
    "ready_pipeline = Pipeline(steps=[\n",
    "    ('imputer' , SimpleImputer(strategy='most_frequent')),\n",
    "])\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "all_pipeline = ColumnTransformer(transformers=[\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', categ_pipline, categ_cols),\n",
    "    ('ready', ready_pipeline, ready_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1912bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply\n",
    "X_train_final = all_pipeline.fit_transform(X_train)\n",
    "X_test_final = all_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801a6f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix class weight calculation\n",
    "vals_count = np.bincount(y_train) / len(y_train)\n",
    "\n",
    "# Create balanced class weights (inverse of frequency)\n",
    "dict_wieght = {}\n",
    "for i in range(2):\n",
    "    dict_wieght[i] = 1.0 / vals_count[i] if vals_count[i] > 0 else 1.0\n",
    "\n",
    "# Normalize weights\n",
    "total_weight = sum(dict_wieght.values())\n",
    "for i in range(2):\n",
    "    dict_wieght[i] = dict_wieght[i] / total_weight\n",
    "\n",
    "## 3. Using SMOTE for over sampling\n",
    "over = SMOTE(sampling_strategy=0.7)\n",
    "X_train_resmapled, y_train_resampled = over.fit_resample(X_train_final, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d4f1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train , y_train , plot_name = '', class_weight = None ):\n",
    "    global clf_name\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight=class_weight)\n",
    "    clf.fit(X_train , y_train)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test_final)\n",
    "    f1_score_train = f1_score(y_train , y_pred_train)\n",
    "    f1_score_test = f1_score(y_test , y_pred_test)\n",
    "    clf_name = clf.__class__.__name__\n",
    "    ## Plot the confusion matrix \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred_test), annot=True, cbar=False, fmt='.2f', cmap='Blues')\n",
    "    plt.title(f'{plot_name}')\n",
    "    plt.xticks(ticks=np.arange(2) + 0.5, labels=[False, True])\n",
    "    plt.yticks(ticks=np.arange(2) + 0.5, labels=[False, True])\n",
    "    ## Save the plot locally\n",
    "    plt.savefig(f'{plot_name}.png', bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    ## Write scores to a file\n",
    "    with open('metrics.txt', 'a') as f:\n",
    "        f.write(f'{clf_name} {plot_name}\\n')\n",
    "        f.write(f\"F1-score of Training is: {f1_score_train*100:.2f} %\\n\")\n",
    "        f.write(f\"F1-Score of Validation is: {f1_score_test*100:.2f} %\\n\")\n",
    "        f.write('----'*10 + '\\n')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe01a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1- train model without use imblancing handle \n",
    "train_model(X_train_final , y_train , plot_name = 'Without Imbalance Handle' , class_weight = None)\n",
    "\n",
    "## 2 - train model with use imblancing handle (class_weight)\n",
    "train_model(X_train_final , y_train , plot_name = 'With Imbalance Handle (class_weight)' , class_weight = dict_wieght)\n",
    "\n",
    "## 3- train model with use imblancing handle (SMOTE)\n",
    "train_model(X_train_resmapled , y_train_resampled , plot_name = 'With Imbalance Handle (SMOTE)' , class_weight = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996a1b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine all conf matrix in one\n",
    "confusion_matrix_paths = ['./Without Imbalance Handle.png', './With Imbalance Handle (class_weight).png', './With Imbalance Handle (SMOTE).png']\n",
    "\n",
    "## Load and plot each confusion matrix\n",
    "plt.figure(figsize=(15, 5))  # Adjust figure size as needed\n",
    "for i, path in enumerate(confusion_matrix_paths, 1):\n",
    "    img = Image.open(path)\n",
    "    plt.subplot(1, len(confusion_matrix_paths), i)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')  # Disable axis for cleaner visualization\n",
    "\n",
    "\n",
    "## Save combined plot locally\n",
    "plt.suptitle(clf_name, fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.savefig(f'conf_matrix.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "## Delete old image files\n",
    "for path in confusion_matrix_paths:\n",
    "    os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c164e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
